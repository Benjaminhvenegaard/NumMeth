<HTML>



<HEAD>



<TITLE>Pattern Recognition with Neural Networks in C++</TITLE>



</HEAD>



<BODY>



<H1><A NAME="top"></A>Pattern Recognition with Neural Networks

in C++ </H1>



<H3>Authors - Abhijit S. Pandya and Robert B. Macy</H3>



<P>

<I>Computer Science and Engineering Department, Florida Atlantic

University, Boca Raton</I> <HR>



<P>

<A HREF="#des">Description</A> | <A HREF="#fea">Features</A> |

<A HREF="#con">Contents</A> | <A HREF="#aud">Audience</A> | <A HREF="#pub">Publi
cation Information and Price</A>

<HR>



<H3><A NAME="des">Description</A></H3>



<P>

The addition of artificial neural network computing to traditional

pattern recognition has given rise to a new, different, and more

powerful methodology that is presented in this interesting book.

This is a practical guide to the application of artificial neural

networks.

<P>

Geared toward the practitioner, <B>Pattern Recognition with Neural

Networks in C++</B> covers pattern classification and neural network

approaches within the same framework. Through the book's presentation

of underlying theory and numerous practical examples, readers

gain an understanding that will allow them to make judicious design

choices rendering neural application predictable and effective.

The book provides an intuitive explanation of each method for

each network paradigm. This discussion is supported by a rigorous

mathematical approach where necessary.

<P>

C++ has emerged as a rich and descriptive means by which concepts,

models, or algorithms can be precisely described. For many of

the neural network models discussed, C++ programs are presented

for the actual implementation. Pictorial diagrams and in-depth

discussions explain each topic. Necessary derivative steps for

the mathematical models are included so that readers can incorporate

new ideas into their programs as the field advances with new developments.

For each approach, the authors clearly state the known theoretical

results, the known tendencies of the approach, and their recommendations

for getting the best results from the method.

<P>

The material covered in the book is accessible to working engineers

with little or no explicit background in neural networks. However,

the material is presented in sufficient depth so that those with

prior knowledge will find this book beneficial. <B>Pattern Recognition

with Neural Networks in C++</B> is also suitable for courses in

neural networks at an advanced undergraduate or graduate level.

This book is valuable for academic as well as practical research.

<P>

<A href=#top>Go to Top</A> <HR>



<H3><A NAME="fea">Features</A></H3>



<UL>

<LI>Provides complete code that will assist experimental design

<LI>Unlike other books, this one covers neural network methodologies

and details the pattern recognition problem

<LI>Allows readers to make a wiser design choice with a predictable

and effective neural application

<LI>Written in a style accessible to both novices and experienced

practitioners

</UL>



<P>

<B>Includes a 3.5&quot;, IBM compatible, diskette containing the

programs within in the book</B> 

<P>

<A href=#top>Go to Top</A> <HR>



<H3><A NAME="aud">Audience</A></H3>



<P>

Advanced undergraduate and graduate levels in computer science

and most engineering specialties. Suitable text for a course in

pattern recognition with emphasis on neural methods or in combination

with text on statistical methods.

<P>

<A href=#top>Go to Top</A> <HR>



<H3><A NAME="con">Contents</A></H3>



<P>

<B>Introduction</B> 

<UL>

<LI>Pattern Recognition Systems

<LI>Motivation for Artificial Neural Network Approach

<LI>A Prelude to Pattern Recognition

<LI>Statistical Pattern Recognition

<LI>Syntactic Pattern Recognition

<LI>The Character Recognition Problem

<LI>Organization of Topics

</UL>



<P>

<B>Neural Networks: An Overview</B> 

<UL>

<LI>Motivation for Overviewing Biological Neural Networks

<LI>Background

<LI>Biological Neural Networks

<LI>Hierarchical Organization of the Brain

<LI>Historical Background

<LI>Artificial Neural Networks

</UL>



<P>

<B>Preprocessing</B> 

<UL>

<LI>General

<LI>Dealing with Input from a Scanned Image

<LI>Image Compression

<LI>Edge Detection

<LI>Skeletonizing

<LI>Dealing with Input from a Tablet

<LI>Segmentation

</UL>



<P>

<B>Feed Forward Networks with Supervised Learning</B> 

<UL>

<LI>Feed-Forward Multilayer Perceptron (FFMLP) Architecture

<LI>FFMLP in C++

<LI>Training with Back Propagation

<LI>A Primitive Example

<LI>Training Strategies and Avoiding Local Minima

<LI>Variations on Gradient Descent

<LI>Topology

<LI>ACON vs. OCON

<LI>Overtraining and Generalization

<LI>Training Set Size and Network Size

<LI>Conjugate Gradient Method

<LI>ALOPEX

</UL>



<P>

<B>Some Other Types of Neural Networks</B> 

<UL>

<LI>General

<LI>Radial Basis Function Networks

<LI>Higher Order Neural Networks

</UL>



<P>

<B>Feature Extraction I: Geometric Features and Transformations</B>



<UL>

<LI>General

<LI>Geometric Features (Loops, Intersections and Endpoints)

<LI>Feature Maps

<LI>A Network Example Using Geometric Features

<LI>Feature Extraction Using Transformations

<LI>Fourier Descriptors

<LI>Gabor Transformations and Wavelets

</UL>



<P>

<B>Feature Extraction II: Principle Component Analysis</B> 

<UL>

<LI>Dimensionality Reduction

<LI>Principal Components

<LI>Karhunen-Loeve (K-L) Transformation

<LI>Principal Component Neural Networks

<LI>Applications

</UL>



<P>

<B>Kohonen Networks and Learning Vector Quantization</B> 

<UL>

<LI>General

<LI>K-Means Algorithm

<LI>An Introduction to the Kohonen Model

<LI>The Role of Lateral Feedback

<LI>Kohonen Self-Organizing Feature Map

<LI>Learning Vector Quantization

<LI>Variations on LVQ

</UL>



<P>

<B>Neural Associative Memories and Hopfield Networks</B> 

<UL>

<LI>General

<LI>Linear Associative Memory (LAM)

<LI>Hopfield Networks

<LI>A Hopfield Example

<LI>Discussion

<LI>Bit Map Example

<LI>BAM Networks

<LI>A BAM Example

</UL>



<P>

<B>Adaptive Resonance Theory (ART)</B> 

<UL>

<LI>General

<LI>Discovering the Cluster Structure

<LI>Vector Quantization

<LI>ART Philosophy

<LI>The Stability-Plasticity Dilemma

<LI>Art1: Basic Operation

<LI>Art1: Algorithm

<LI>The Gain Control Mechanism

<LI>ART2 Model

<LI>Discussion

<LI>Applications

</UL>



<P>

<B>Neocognition</B> 

<UL>

<LI>Introduction

<LI>Architecture

<LI>Example of a System with Sample Training Patterns

</UL>



<P>

<B>Systems with Multiple Classifiers</B> 

<UL>

<LI>General

<LI>A Framework for Combining Multiple Recognizers

<LI>Voting Schemes

<LI>The Confusion Matrix

<LI>Reliability

<LI>Some Empirical Approaches

</UL>



<P>

<A href=#top>Go to Top</A> <HR>



<H3><A NAME="pub">Publication and Pricing</A></H3>



<P>

Catalog number <B>9462 WGBA</B> 

<P>

October 1995, 432 pp., ISBN: 0-8493-9462-7

<p>For orders, <a href="mailto:orders@crcpress.com">contact our order department
,</a> or visit the <a href="http://www.crcpress.com">CRC Press Home Page</a>


</BODY>



</HTML>


